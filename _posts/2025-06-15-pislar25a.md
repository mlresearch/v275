---
title: Combining Causal Models for More Accurate Abstractions of Neural Networks
booktitle: Proceedings of the Fourth Conference on Causal Learning and Reasoning
year: '2025'
volume: '275'
series: Proceedings of Machine Learning Research
month: 5
publisher: PMLR
openreview: mVftlEi1CD
abstract: Mechanistic interpretability aims to reverse engineer neural networks by
  uncovering which high-level algorithms they implement. Causal abstraction provides
  a precise notion of when a network implements an algorithm, i.e., a causal model
  of the network contains low-level features that realize the high-level variables
  in a causal model of the algorithm (Geiger et al., 2024). A typical problem in practical
  settings is that the algorithm is not an entirely faithful abstraction of the network,
  i.e., it only partially captures true reasoning process of a model. We propose a
  solution where we combine different simple high-level models to produce a more faithful
  representation of the network. Through learning this combination, we can model neural
  networks as being in different computational states depending on the input provided,
  which we show is more accurate to GPT-2 small fine-tuned on two toy tasks. We observe
  a trade off between the strength of an interpretability hypothesis, which we define
  in terms of the number of inputs explained by the high-level models, and its faithfulness,
  which we define as the interchange intervention accuracy. Our method allows us to
  modulate between the two, providing the most accurate combination of models that
  describe the behavior of a neural network given a faithfulness level.
layout: inproceedings
issn: 2640-3498
id: pislar25a
tex_title: Combining Causal Models for More Accurate Abstractions of Neural Networks
firstpage: 114
lastpage: 138
page: 114-138
order: 114
cycles: false
bibtex_editor: Huang, Biwei and Drton, Mathias
editor:
- given: Biwei
  family: Huang
- given: Mathias
  family: Drton
bibtex_author: P\^{i}slar, Theodora-Mara and Magliacane, Sara and Geiger, Atticus
author:
- given: Theodora-Mara
  family: PÃ®slar
- given: Sara
  family: Magliacane
- given: Atticus
  family: Geiger
date: 2025-06-15
address:
container-title: Proceedings of the Fourth Conference on Causal Learning and Reasoning
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 6
  - 15
pdf: https://raw.githubusercontent.com/mlresearch/v275/main/assets/pislar25a/pislar25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
