---
title: Interpretable Neural Causal Models with TRAM-DAGs
booktitle: Proceedings of the Fourth Conference on Causal Learning and Reasoning
year: '2025'
volume: '275'
series: Proceedings of Machine Learning Research
month: 5
publisher: PMLR
openreview: h3DDKFCOTq
abstract: 'The ultimate goal of most scientific studies is to understand the underlying
  causal mechanism between the involved variables. Structural causal models (SCMs)
  are widely used to represent such causal mechanisms. Given an SCM, causal queries
  on all three levels of Pearl’s causal hierarchy can be answered: $\mathcal{L}_1$
  observational, $\mathcal{L}_2$ interventional, and $\mathcal{L}_3$ counterfactual.
  An essential aspect of modeling the SCM is to model the dependency of each variable
  on its causal parents. Traditionally this is done by parametric statistical models,
  such as linear or logistic regression models. This allows to handle all kinds of
  data types and fit interpretable models but bears the risk of introducing a bias
  due to the assumed rigid functional form. More recently neural causal models came
  up using neural networks (NNs) to model the causal relationships, allowing the estimation
  of nearly any underlying functional form without bias. However, current neural causal
  models are generally restricted to continuous variables and do not yield an interpretable
  form of the causal relationships. Transformation models range from simple statistical
  regressions to complex networks and can handle continuous, ordinal, and binary data.
  Here, we propose to use TRAMs to model the functional relationships in SCMs allowing
  us to bridge the gap between interpretability and flexibility in causal modeling.
  We call this method TRAM-DAG and assume currently that the underlying directed acyclic
  graph (DAG) is known. For the fully observed case, we benchmark TRAM-DAGs against
  state-of-the-art statistical and NN-based causal models. We show that TRAM-DAGs
  are interpretable but also achieve equal or superior performance in queries ranging
  from $\mathcal{L}_1$ to $\mathcal{L}_3$ in the causal hierarchy.  For the continuous
  case, TRAM-DAGs allow for counterfactual queries for three common causal structures,
  including unobserved confounding.'
layout: inproceedings
issn: 2640-3498
id: sick25a
tex_title: Interpretable Neural Causal Models with TRAM-DAGs
firstpage: 606
lastpage: 630
page: 606-630
order: 606
cycles: false
bibtex_editor: Huang, Biwei and Drton, Mathias
editor:
- given: Biwei
  family: Huang
- given: Mathias
  family: Drton
bibtex_author: Sick, Beate and D\"{u}rr, Oliver
author:
- given: Beate
  family: Sick
- given: Oliver
  family: Dürr
date: 2025-06-15
address:
container-title: Proceedings of the Fourth Conference on Causal Learning and Reasoning
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 6
  - 15
pdf: https://raw.githubusercontent.com/mlresearch/v275/main/assets/sick25a/sick25a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
